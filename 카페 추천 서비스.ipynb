{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9096decf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#데이터-수집\" data-toc-modified-id=\"데이터-수집-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>데이터 수집</a></span><ul class=\"toc-item\"><li><span><a href=\"#네이버-지도-리뷰-수집\" data-toc-modified-id=\"네이버-지도-리뷰-수집-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>네이버 지도 리뷰 수집</a></span><ul class=\"toc-item\"><li><span><a href=\"#네이버-지도-리뷰-URL-수집\" data-toc-modified-id=\"네이버-지도-리뷰-URL-수집-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>네이버 지도 리뷰 URL 수집</a></span></li><li><span><a href=\"#네이버-지도-리뷰-수집\" data-toc-modified-id=\"네이버-지도-리뷰-수집-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>네이버 지도 리뷰 수집</a></span></li></ul></li><li><span><a href=\"#네이버-블로그-리뷰-수집\" data-toc-modified-id=\"네이버-블로그-리뷰-수집-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>네이버 블로그 리뷰 수집</a></span><ul class=\"toc-item\"><li><span><a href=\"#블로그-URL-수집\" data-toc-modified-id=\"블로그-URL-수집-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>블로그 URL 수집</a></span></li><li><span><a href=\"#블로그-리뷰-크롤링\" data-toc-modified-id=\"블로그-리뷰-크롤링-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>블로그 리뷰 크롤링</a></span></li><li><span><a href=\"#블로그-리뷰-전처리---이모지-제거\" data-toc-modified-id=\"블로그-리뷰-전처리---이모지-제거-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>블로그 리뷰 전처리 - 이모지 제거</a></span></li></ul></li><li><span><a href=\"#카페-기본-정보-수집\" data-toc-modified-id=\"카페-기본-정보-수집-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>카페 기본 정보 수집</a></span></li><li><span><a href=\"#데이터-최종본-만들기\" data-toc-modified-id=\"데이터-최종본-만들기-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>데이터 최종본 만들기</a></span></li></ul></li><li><span><a href=\"#데이터-분석\" data-toc-modified-id=\"데이터-분석-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>데이터 분석</a></span><ul class=\"toc-item\"><li><span><a href=\"#‘카공’하기-좋은-카페의-기준/키워드-선정-방법\" data-toc-modified-id=\"‘카공’하기-좋은-카페의-기준/키워드-선정-방법-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>‘카공’하기 좋은 카페의 기준/키워드 선정 방법</a></span><ul class=\"toc-item\"><li><span><a href=\"#각-기준별-명사-키워드-선정\" data-toc-modified-id=\"각-기준별-명사-키워드-선정-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>각 기준별 명사 키워드 선정</a></span><ul class=\"toc-item\"><li><span><a href=\"#기준-1:-공부하기-좋아요\" data-toc-modified-id=\"기준-1:-공부하기-좋아요-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>기준 1: 공부하기 좋아요</a></span></li><li><span><a href=\"#기준-2:-조용한-분위기예요\" data-toc-modified-id=\"기준-2:-조용한-분위기예요-2.1.1.2\"><span class=\"toc-item-num\">2.1.1.2&nbsp;&nbsp;</span>기준 2: 조용한 분위기예요</a></span></li><li><span><a href=\"#기준-3:-콘센트가-많아요\" data-toc-modified-id=\"기준-3:-콘센트가-많아요-2.1.1.3\"><span class=\"toc-item-num\">2.1.1.3&nbsp;&nbsp;</span>기준 3: 콘센트가 많아요</a></span></li><li><span><a href=\"#기준-4:-역에서-가까워요\" data-toc-modified-id=\"기준-4:-역에서-가까워요-2.1.1.4\"><span class=\"toc-item-num\">2.1.1.4&nbsp;&nbsp;</span>기준 4: 역에서 가까워요</a></span></li><li><span><a href=\"#고민했던-기준:-영업-시간이-길어요\" data-toc-modified-id=\"고민했던-기준:-영업-시간이-길어요-2.1.1.5\"><span class=\"toc-item-num\">2.1.1.5&nbsp;&nbsp;</span>고민했던 기준: 영업 시간이 길어요</a></span></li><li><span><a href=\"#고민했던-기준:-의자가-편안해요\" data-toc-modified-id=\"고민했던-기준:-의자가-편안해요-2.1.1.6\"><span class=\"toc-item-num\">2.1.1.6&nbsp;&nbsp;</span>고민했던 기준: 의자가 편안해요</a></span></li><li><span><a href=\"#기준-5:-좌석이-많아요\" data-toc-modified-id=\"기준-5:-좌석이-많아요-2.1.1.7\"><span class=\"toc-item-num\">2.1.1.7&nbsp;&nbsp;</span>기준 5: 좌석이 많아요</a></span></li><li><span><a href=\"#기준-6:-와이파이가-빨라요\" data-toc-modified-id=\"기준-6:-와이파이가-빨라요-2.1.1.8\"><span class=\"toc-item-num\">2.1.1.8&nbsp;&nbsp;</span>기준 6: 와이파이가 빨라요</a></span></li><li><span><a href=\"#기준-7:-테이블이-넓어요\" data-toc-modified-id=\"기준-7:-테이블이-넓어요-2.1.1.9\"><span class=\"toc-item-num\">2.1.1.9&nbsp;&nbsp;</span>기준 7: 테이블이 넓어요</a></span></li></ul></li><li><span><a href=\"#지도-리뷰와-블로그-리뷰-합치기\" data-toc-modified-id=\"지도-리뷰와-블로그-리뷰-합치기-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>지도 리뷰와 블로그 리뷰 합치기</a></span></li><li><span><a href=\"#각-기준별-명사-키워드와-함께-자주-쓰이는-형용사,-부사-확인\" data-toc-modified-id=\"각-기준별-명사-키워드와-함께-자주-쓰이는-형용사,-부사-확인-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>각 기준별 명사 키워드와 함께 자주 쓰이는 형용사, 부사 확인</a></span><ul class=\"toc-item\"><li><span><a href=\"#기준-1:-공부하기-좋아요\" data-toc-modified-id=\"기준-1:-공부하기-좋아요-2.1.3.1\"><span class=\"toc-item-num\">2.1.3.1&nbsp;&nbsp;</span>기준 1: 공부하기 좋아요</a></span></li><li><span><a href=\"#기준-3:-콘센트가-많아요\" data-toc-modified-id=\"기준-3:-콘센트가-많아요-2.1.3.2\"><span class=\"toc-item-num\">2.1.3.2&nbsp;&nbsp;</span>기준 3: 콘센트가 많아요</a></span></li><li><span><a href=\"#기준-5:-좌석이-많아요\" data-toc-modified-id=\"기준-5:-좌석이-많아요-2.1.3.3\"><span class=\"toc-item-num\">2.1.3.3&nbsp;&nbsp;</span>기준 5: 좌석이 많아요</a></span></li><li><span><a href=\"#기준-6:-와이파이가-빨라요\" data-toc-modified-id=\"기준-6:-와이파이가-빨라요-2.1.3.4\"><span class=\"toc-item-num\">2.1.3.4&nbsp;&nbsp;</span>기준 6: 와이파이가 빨라요</a></span></li><li><span><a href=\"#기준-7:-테이블이-넓어요\" data-toc-modified-id=\"기준-7:-테이블이-넓어요-2.1.3.5\"><span class=\"toc-item-num\">2.1.3.5&nbsp;&nbsp;</span>기준 7: 테이블이 넓어요</a></span></li></ul></li></ul></li><li><span><a href=\"#'카공'-지수-도출-방법\" data-toc-modified-id=\"'카공'-지수-도출-방법-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>'카공' 지수 도출 방법</a></span><ul class=\"toc-item\"><li><span><a href=\"#카페별-키워드가-들어간-리뷰의-개수와-전체-리뷰-간의-비율-도출\" data-toc-modified-id=\"카페별-키워드가-들어간-리뷰의-개수와-전체-리뷰-간의-비율-도출-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>카페별 키워드가 들어간 리뷰의 개수와 전체 리뷰 간의 비율 도출</a></span><ul class=\"toc-item\"><li><span><a href=\"#기준-1:-공부하기-좋아요\" data-toc-modified-id=\"기준-1:-공부하기-좋아요-2.2.1.1\"><span class=\"toc-item-num\">2.2.1.1&nbsp;&nbsp;</span>기준 1: 공부하기 좋아요</a></span></li><li><span><a href=\"#기준-2:-조용한-분위기예요\" data-toc-modified-id=\"기준-2:-조용한-분위기예요-2.2.1.2\"><span class=\"toc-item-num\">2.2.1.2&nbsp;&nbsp;</span>기준 2: 조용한 분위기예요</a></span></li><li><span><a href=\"#기준-3:-콘센트가-많아요\" data-toc-modified-id=\"기준-3:-콘센트가-많아요-2.2.1.3\"><span class=\"toc-item-num\">2.2.1.3&nbsp;&nbsp;</span>기준 3: 콘센트가 많아요</a></span></li><li><span><a href=\"#기준-5:-좌석이-많아요\" data-toc-modified-id=\"기준-5:-좌석이-많아요-2.2.1.4\"><span class=\"toc-item-num\">2.2.1.4&nbsp;&nbsp;</span>기준 5: 좌석이 많아요</a></span></li><li><span><a href=\"#기준-6:-와이파이가-빨라요\" data-toc-modified-id=\"기준-6:-와이파이가-빨라요-2.2.1.5\"><span class=\"toc-item-num\">2.2.1.5&nbsp;&nbsp;</span>기준 6: 와이파이가 빨라요</a></span></li><li><span><a href=\"#기준-7:-테이블이-넓어요\" data-toc-modified-id=\"기준-7:-테이블이-넓어요-2.2.1.6\"><span class=\"toc-item-num\">2.2.1.6&nbsp;&nbsp;</span>기준 7: 테이블이 넓어요</a></span></li></ul></li><li><span><a href=\"#기준-4:-역에서-가까워요-분석\" data-toc-modified-id=\"기준-4:-역에서-가까워요-분석-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>기준 4: 역에서 가까워요 분석</a></span></li><li><span><a href=\"#네이버-'이런-점이-좋았어요'-분석\" data-toc-modified-id=\"네이버-'이런-점이-좋았어요'-분석-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>네이버 '이런 점이 좋았어요' 분석</a></span></li></ul></li><li><span><a href=\"#최종-카공-점수-계산\" data-toc-modified-id=\"최종-카공-점수-계산-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>최종 카공 점수 계산</a></span></li></ul></li><li><span><a href=\"#데이터-시각화\" data-toc-modified-id=\"데이터-시각화-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>데이터 시각화</a></span><ul class=\"toc-item\"><li><span><a href=\"#카공-전체-점수\" data-toc-modified-id=\"카공-전체-점수-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>카공 전체 점수</a></span></li><li><span><a href=\"#카공-기준별-점수\" data-toc-modified-id=\"카공-기준별-점수-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>카공 기준별 점수</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb28e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import nltk\n",
    "import konlpy, nltk\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import ast\n",
    "from matplotlib import pyplot as plt\n",
    "okt = konlpy.tag.Okt()\n",
    "kk = konlpy.tag.Kkma()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec82a30",
   "metadata": {},
   "source": [
    "# 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f54d2",
   "metadata": {},
   "source": [
    "## 네이버 지도 리뷰 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946a051",
   "metadata": {},
   "source": [
    "### 네이버 지도 리뷰 URL 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b204272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Explicit Wait\n",
    "import selenium, bs4, tqdm\n",
    "from selenium                          import webdriver\n",
    "from webdriver_manager.chrome          import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by  import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support    import expected_conditions as EC\n",
    "from selenium.common.exceptions    import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d24f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브라우저를 열고 검색 창에 검색어를 입력하는 함수\n",
    "def initialize():\n",
    "    browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    url = 'https://map.naver.com'\n",
    "\n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    element = browser.find_element(By.CLASS_NAME, 'input_search')\n",
    "    time.sleep(1)\n",
    "\n",
    "    element.send_keys('서울대입구 카페')\n",
    "\n",
    "    # 검색창을 실행한다.\n",
    "    element.send_keys(Keys.ENTER)\n",
    "\n",
    "    # 검색결과 frame으로 이동\n",
    "    time.sleep(1)\n",
    "\n",
    "    iframe = browser.find_element(By.ID, 'searchIframe')\n",
    "    browser.switch_to.frame(iframe)\n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe1a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색창 스크롤 후 클릭할 대상 가져오는 함수\n",
    "def getClickElement(browser):\n",
    "    div = browser.find_element(By.XPATH, '//*[@id=\"_pcmap_list_scroll_container\"]')\n",
    "    last_height = browser.execute_script(\"return arguments[0].scrollHeight;\", div)\n",
    "    while True:\n",
    "        browser.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", div);\n",
    "        time.sleep(1)\n",
    "        new_height = browser.execute_script(\"return arguments[0].scrollHeight;\", div)\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    bs = bs4.BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    click_list = bs.find_all('li', '_1EKsQ _12tNp')\n",
    "    shown_list = bs.find_all('li', '_1EKsQ _12tNp _3in-q')\n",
    "\n",
    "    click_element_list = click_list+ shown_list\n",
    "    return list(set(click_element_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과 창에서 각 결과 클릭 후 리뷰 페이지 url 가져오는 함수\n",
    "def getReviewUrl (browser, click_element_list):\n",
    "    review_url = []\n",
    "    for i in tqdm(range(1, len(click_element_list)+1)):  \n",
    "        click_item = browser.find_element(By.XPATH, f'//*[@id=\"_pcmap_list_scroll_container\"]/ul/li[{i}]/div[1]/a/div[1]')\n",
    "        click_item.click()\n",
    "        time.sleep(1)\n",
    "        browser.switch_to.parent_frame()\n",
    "        time.sleep(1)\n",
    "        entryFrame = browser.find_element(By.ID, 'entryIframe')\n",
    "        WebDriverWait(browser, 10).until(EC.frame_to_be_available_and_switch_to_it(entryFrame))\n",
    "\n",
    "        bs = bs4.BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        review_button = bs.find('a', '_2RG_o')\n",
    "        review_url.append(review_button.attrs['href'])\n",
    "        browser.switch_to.parent_frame()\n",
    "        iframe = browser.find_element(By.ID, 'searchIframe')\n",
    "        browser.switch_to.frame(iframe)\n",
    "#     browser.quit()\n",
    "    return review_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a22a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 페이지  url 가져오기\n",
    "\n",
    "cafe_name = []\n",
    "cafe_rating = []\n",
    "cafe_short_reviews = []\n",
    "cafe_reviews = []\n",
    "\n",
    "review_url = []\n",
    "\n",
    "click_num = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    browser = initialize()\n",
    "    move_buttons = browser.find_elements(By.CLASS_NAME, '_2bgjK')\n",
    "    \n",
    "    for button in move_buttons:\n",
    "        if(button.text == '다음페이지'):\n",
    "            for i in range(0, click_num):\n",
    "                button.click()\n",
    "                time.sleep(1)\n",
    "            try:\n",
    "                last_button = browser.find_element(By.CLASS_NAME, '_34lTS')\n",
    "            except: \n",
    "                print('click_num', click_num)\n",
    "    clickElements = getClickElement(browser)\n",
    "    review_url += getReviewUrl(browser, clickElements)\n",
    "        \n",
    "    #마지막버튼체크\n",
    "\n",
    "    if(last_button.text == '다음페이지'):\n",
    "        break\n",
    "        \n",
    "    click_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 url 저장\n",
    "df = pandas.DataFrame(review_url)\n",
    "df\n",
    "\n",
    "df.to_csv('서울대입구카페url.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306beedb",
   "metadata": {},
   "source": [
    "### 네이버 지도 리뷰 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37da10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 페이지 url 들어가서 카페 이름, 평점, 짧은 리뷰, 긴리뷰 가져오는 함수\n",
    "\n",
    "def getReviews(url):\n",
    "    baseUrl = 'https://pcmap.place.naver.com'\n",
    "\n",
    "    cafe_name = []\n",
    "    cafe_short_review = []\n",
    "    cafe_review = []\n",
    "    cafe_rating = []\n",
    "\n",
    "    browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    browser.get(baseUrl + url)\n",
    "    time.sleep(1)\n",
    "    name = browser.find_element(By.CLASS_NAME, '_3XamX')\n",
    "    cafe_name.append(name.text)\n",
    "    time.sleep(1)\n",
    "    review_tab = browser.find_elements(By.CLASS_NAME, '_2RG_o')\n",
    "    for tab in review_tab:\n",
    "        if tab.text == '리뷰':\n",
    "            tab.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    #평점 가져오기\n",
    "    try:\n",
    "        rating = browser.find_element(By.CLASS_NAME, 'Sv1wj')\n",
    "        cafe_rating.append(rating.text)\n",
    "    except NoSuchElementException:\n",
    "        cafe_rating.append('평점 없음')\n",
    "\n",
    "\n",
    "    ## 짧은 리뷰 탭 열기\n",
    "    try:\n",
    "        ## 리뷰 수가 적어서 짧은 리뷰 없는 경우 핸들링\n",
    "        no_review = browser.find_element(By.CLASS_NAME, '_2NW-t')\n",
    "        cafe_short_review.append('짧은 리뷰 없음')\n",
    "    except NoSuchElementException:\n",
    "        try:\n",
    "            while True:\n",
    "                open_tab = browser.find_element(By.CLASS_NAME, '_22igH')\n",
    "                open_tab.click()\n",
    "        except NoSuchElementException:\n",
    "\n",
    "        #짧은 리뷰 가져오기\n",
    "            bs_short_reviews = bs4.BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            short_review_text = bs_short_reviews.find_all('span', '_1lntw')\n",
    "            short_review_ratings = bs_short_reviews.find_all('span', 'Nqp-s')[1:]\n",
    "            cafe_short_review.append(dict(zip([element.get_text(strip=True) for element in short_review_text], [element.get_text(strip=True)[13:] for element in short_review_ratings])))\n",
    "    ## 긴 리뷰 가져오기\n",
    "    try:\n",
    "\n",
    "    ## 긴 리뷰 더보기 탭 열기\n",
    "        while True:\n",
    "            more_tab = browser.find_element(By.CLASS_NAME, '_3iTUo')\n",
    "            more_tab.click()\n",
    "            time.sleep(1)\n",
    "    except (StaleElementReferenceException, NoSuchElementException):\n",
    "        open_review = browser.find_elements(By.CLASS_NAME, 'M_704')\n",
    "\n",
    "        ## 리뷰들 다 열기\n",
    "        for tab in open_review:\n",
    "            browser.execute_script(\"arguments[0].click()\", tab)\n",
    "\n",
    "        ## 리뷰 가져오기\n",
    "        bs_reviews = bs4.BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        reviews = bs_reviews.find_all('span', 'WoYOw')\n",
    "        cafe_review.append([review.get_text(strip=True) for review in reviews])\n",
    "        browser.close()\n",
    "    \n",
    "    return cafe_name, cafe_rating, cafe_short_review, cafe_review                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 url 가져오기\n",
    "\n",
    "df = pandas.read_csv('./서울대입구카페url.csv')\n",
    "len(list(df['0']))\n",
    "\n",
    "review_url = list(df['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d627819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 url로 리뷰, 평점, 카페이름, 짧은 리뷰 가져오기\n",
    "cafe_name = []\n",
    "cafe_rating = []\n",
    "cafe_short_reviews = []\n",
    "cafe_reviews = []\n",
    "\n",
    "\n",
    "for url in tqdm(review_url):\n",
    "    name, rating, short_reviews, reviews = getReviews(url)\n",
    "    cafe_name += name\n",
    "    cafe_rating += rating\n",
    "    cafe_short_reviews += short_reviews\n",
    "    cafe_reviews += reviews\n",
    "    print(name, len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73bb9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 결과 엑셀로 저장\n",
    "d = {'이름': cafe_name, '평점': cafe_rating, '짧은 리뷰': cafe_short_reviews, '리뷰': cafe_reviews}\n",
    "\n",
    "df = pandas.DataFrame(d)\n",
    "\n",
    "df.to_excel('네이버 지도 리뷰 데이터.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887174af",
   "metadata": {},
   "source": [
    "## 네이버 블로그 리뷰 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37097489",
   "metadata": {},
   "source": [
    "### 블로그 URL 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지도 리뷰 url 가져오기\n",
    "\n",
    "df = pandas.read_csv('./서울대입구카페url.csv')\n",
    "review_url = list(df['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 카페별 블로그 리뷰 URL 가져오기\n",
    "baseUrl = 'https://pcmap.place.naver.com'\n",
    "\n",
    "total_blog_link = []\n",
    "\n",
    "for url in tqdm(review_url):\n",
    "    browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    blog_url = baseUrl + url\n",
    "    \n",
    "    browser.get(blog_url)\n",
    "    time.sleep(1)\n",
    "    name = browser.find_element(By.CLASS_NAME, '_3XamX')\n",
    "    title = name.text\n",
    "    review_tab = browser.find_elements(By.CLASS_NAME, '_2RG_o')\n",
    "    for tab in review_tab:\n",
    "        if tab.text == '리뷰':\n",
    "            tab.click()\n",
    "    time.sleep(1)\n",
    "    blog_tab = browser.find_elements(By.CLASS_NAME, '_85GDZ')\n",
    "    \n",
    "    for tab in blog_tab:\n",
    "        if tab.text == '블로그 리뷰':\n",
    "            tab.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    blog_link = []\n",
    "\n",
    "    try:\n",
    "        # 블로그 리뷰들 열기\n",
    "        while True:\n",
    "            more_tab = browser.find_element(By.CLASS_NAME, '_3iTUo')\n",
    "            more_tab.click()\n",
    "            time.sleep(1)\n",
    "            \n",
    "    except (StaleElementReferenceException, NoSuchElementException):\n",
    "        # 블로그 링크 저장하기\n",
    "        bs = bs4.BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        links = bs.find_all('a', '_1cfgS')\n",
    "        for link in links:\n",
    "            blog_link.append(link.attrs['href'])\n",
    "        \n",
    "    blog_dict = {'name': title, 'link': blog_link}\n",
    "    total_blog_link.append(blog_dict)\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 블로그 url 모음 저장\n",
    "df = pandas.DataFrame(total_blog_link)\n",
    "\n",
    "df.to_csv('네이버 설입 블로그 url.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07bd35e",
   "metadata": {},
   "source": [
    "### 블로그 리뷰 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb45df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 카페별 블로그 url에서 리뷰 가져오기\n",
    "\n",
    "names = list(df['name'])\n",
    "links = list(df['link'])\n",
    "\n",
    "baseUrl = 'https://blog.naver.com'\n",
    "\n",
    "review_list = []\n",
    "\n",
    "for index, link in enumerate(tqdm(links)):\n",
    "    blog_dict = {'name': names[index], 'review': []}\n",
    "    for url in ast.literal_eval(link):\n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            bs = BeautifulSoup(page.text, 'html.parser')\n",
    "            frame = bs.find('iframe', id= \"mainFrame\")\n",
    "            frame_url = baseUrl+frame['src']\n",
    "            page2 = requests.get(frame_url)\n",
    "            bs2 = BeautifulSoup(page2.text, 'html.parser')\n",
    "            blog = bs2.find('div', 'se-main-container')\n",
    "            # 블로그 페이지 마다 html 구조가 달라서 각각의 경우에 대해 핸들링\n",
    "            try:\n",
    "                review = blog.get_text(strip=True)\n",
    "                blog_dict['review'].append(review)\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    blog = bs2.find('div', id='postViewArea')\n",
    "                    review=blog.get_text(strip=True)\n",
    "                    blog_dict['review'].append(review)\n",
    "                except AttributeError:\n",
    "                    blog = bs2.find('div', id='postListBody')\n",
    "                    review=blog.get_text(strip=True)\n",
    "                    blog_dict['review'].append(review)\n",
    "        # 로그인이 필요한 카페글인 경우 핸들링\n",
    "        except TypeError:\n",
    "            continue\n",
    "    review_list.append(blog_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링한 리뷰 저장\n",
    "df2 = pd.DataFrame(review_list)\n",
    "df2.to_csv('네이버 설입 블로그 리뷰.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb66eae",
   "metadata": {},
   "source": [
    "### 블로그 리뷰 전처리 - 이모지 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 블로그 리뷰로 자연어 처리를 하는 중 자꾸 에러가 발생해서 알아보니 블로그 리뷰에 이모지가 많이 있어서 문제가 발생하는 것으로 추측, \n",
    "# 이모지 제거 전처리를 수행함\n",
    "\n",
    "#네이버 설입 블로그 불러오기\n",
    "df1 = pandas.read_csv('네이버 설입 블로그 리뷰_0523.csv', encoding = 'utf-8')\n",
    "df1_new = df1[df1['review'].notnull()]\n",
    "review_list1 = list(df1_new['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                           u\"\\U00010000-\\U0010FFFF\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "\n",
    "processed_reviews = []\n",
    "\n",
    "for review in tqdm(review_list1):\n",
    "    parsed_list= []\n",
    "    parsed = ast.literal_eval(review)\n",
    "    for parsed_review in parsed:\n",
    "        processed = emoji_pattern.sub(r'', parsed_review)\n",
    "        parsed_list.append(processed)\n",
    "    processed_reviews.append(parsed_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedad699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_new['review'] = processed_reviews\n",
    "df1_new\n",
    "\n",
    "df1_new.to_csv('네이버 설입 블로그 리뷰 이모지 제거_0523.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425dc748",
   "metadata": {},
   "source": [
    "## 카페 기본 정보 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 url 가져오기\n",
    "\n",
    "df = pandas.read_csv('./서울대입구카페url.csv')\n",
    "len(list(df['0']))\n",
    "\n",
    "review_url = list(df['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b463c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = 'https://pcmap.place.naver.com'\n",
    "\n",
    "cafe_data = []\n",
    "\n",
    "for url in tqdm(review_url):\n",
    "    browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    browser.get(baseUrl + url)\n",
    "    time.sleep(1)\n",
    "    bs = bs4.BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    \n",
    "    name = bs.find('span', '_3XamX')\n",
    "    location = bs.find('span', '_2yqUQ')\n",
    "    subway = bs.find('div', '_2P6sT')\n",
    "    time_data = ''\n",
    "    try:\n",
    "        tab = browser.find_element(By.CLASS_NAME, '_2ZP3j') \n",
    "        time.sleep(1)\n",
    "        tab.click()\n",
    "        time.sleep(1)\n",
    "        bs2 = bs4.BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        time.sleep(1)\n",
    "        hour_data = bs2.find('a', '_2BDci')\n",
    "        working_hour = hour_data.find_all('span', '_20pEw')\n",
    "        for hour in working_hour:\n",
    "            if '영업 종료' not in hour.text:\n",
    "                time_data += f'{hour.text} '\n",
    "    except:\n",
    "        time_data ='영업 시간 정보 없음'\n",
    "\n",
    "    try:\n",
    "        dic = {'name': name.text, 'location': location.text, 'subway': subway.text, 'time': time_data}\n",
    "    except:\n",
    "        dic = {'name': '정보 없음', 'location': '정보 없음', 'subway': '정보 없음', 'time': '정보 없음'}\n",
    "    cafe_data.append(dic)\n",
    "    browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f630033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(cafe_data)\n",
    "\n",
    "df.to_csv('카페 정보.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9d5d5",
   "metadata": {},
   "source": [
    "## 데이터 최종본 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터와 합치기\n",
    "\n",
    "new = pandas.read_csv('카페 정보.csv', index_col = 0)\n",
    "original = pandas.read_csv('네이버 리뷰 전체_0525.csv', index_col = 0)\n",
    "cols = ['이름', '주소', '근처 역 정보', '영업 시간']\n",
    "new.columns = cols\n",
    "\n",
    "# 역 정보 앞에 있는 호선 제거 \n",
    "new['근처 역 정보'] = new['근처 역 정보'].apply(lambda x: x[1:])\n",
    "\n",
    "new.loc[292]['이름'] = '컴포즈커피 봉천더울림메트로점 2'\n",
    "\n",
    "unique_new = new.drop_duplicates('이름')\n",
    "\n",
    "merged =pd.merge(original, unique_new, on=\"이름\", how='left')\n",
    "\n",
    "merged.to_csv('네이버 데이터 최종.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d0b7e",
   "metadata": {},
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd540e0",
   "metadata": {},
   "source": [
    "## ‘카공’하기 좋은 카페의 기준/키워드 선정 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4ed1a",
   "metadata": {},
   "source": [
    "### 각 기준별 명사 키워드 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맥락분석 및 human annotator를 진행하여 기준별 명사 키워드를 선정한다.\n",
    "df = pandas.read_excel('네이버 지도 리뷰 데이터_0523.xlsx')\n",
    "df.set_index('Unnamed: 0', inplace=True)\n",
    "df = df[df['리뷰'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 전체를 한 개의 리스트로 만들기\n",
    "import ast\n",
    "\n",
    "nested_list = []\n",
    "for reviews in df['리뷰']:\n",
    "    nested_list.append(ast.literal_eval(reviews))\n",
    "    \n",
    "len(nested_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eaea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 리뷰에서 최빈단어, 단어에 따른 문장 확인해보기\n",
    "all_reviews = nested_list[0]\n",
    "for i in range(1,100):\n",
    "    all_reviews += nested_list[i]\n",
    "joined2 = '. '.join(all_reviews)\n",
    "tags2 = okt.pos(joined2)\n",
    "filtered = [word for word, tag in tags2 if tag in ('Noun', 'Adjective', 'Verb')]\n",
    "\n",
    "text2 = nltk.Text(filtered)\n",
    "fd2 = nltk.FreqDist(text2)\n",
    "print(fd2.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스타벅스 3군데에서 최빈단어, 맥락 확인해보기\n",
    "starbucks = nested_list[57] + nested_list[92] + nested_list[94]\n",
    "joined = '. '.join(starbucks)\n",
    "tags = okt.pos(joined)\n",
    "filtered = [word for word, tag in tags if tag in ('Noun', 'Adjective', 'Verb')]\n",
    "\n",
    "text = nltk.Text(filtered)\n",
    "fd = nltk.FreqDist(text)\n",
    "print(fd.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebcff4",
   "metadata": {},
   "source": [
    "#### 기준 1: 공부하기 좋아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce813439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text.concordance('분위기')\n",
    "# human annotator:'넓어', '넓고', '조용', '공부', '깔끔', '친절', '쾌적', '스터디', '독서실', '콘센트', '넓게', '사람 많음'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5bf14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text.concordance('혼자')\n",
    "# human annotator: '혼자 온 카공족 점령된 곳', '혼자 드셨어요', '혼자 시간 보내는 젊은이 장사진'\n",
    "# human annotator: 혼자는 빼는 게 좋을 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726e8db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text.concordance('노트북')\n",
    "# human annotator:'노트북 작업하기는 좋은데 사람 많음', '노트북하거나 책 보는 사람 많아서', '노트북하기 좋아요', \n",
    "# human annotator:'노트북 놓을 수 있는 긴 테이블 있어 작업하기 편하고'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c19e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 공부\n",
    "for sentence in starbucks:\n",
    "    if '공부' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9311a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 작업\n",
    "for sentence in starbucks:\n",
    "    if '작업' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스터디\n",
    "for sentence in starbucks:\n",
    "    if '스터디' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노트북\n",
    "for sentence in starbucks:\n",
    "    if '노트북' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692de124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카공\n",
    "for sentence in starbucks:\n",
    "    if '카공' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집중\n",
    "for sentence in starbucks:\n",
    "    if '집중' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업무, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '업무' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392bceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과외, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '과외' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f0b25",
   "metadata": {},
   "source": [
    "#### 기준 2: 조용한 분위기예요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('시끄럽지')\n",
    "# '시끄럽지 않아 좋아요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e5f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 조용하다\n",
    "for sentence in starbucks:\n",
    "    if '조용' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음악, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '음악' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141eb99",
   "metadata": {},
   "source": [
    "#### 기준 3: 콘센트가 많아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('콘센트')\n",
    "# '콘센트 꽂을 곳도 많지만', '콘센트 거의 없고', '콘센트 없고', '콘센트 별로 없음'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1324188",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('충전')\n",
    "# '카드 충전'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('코드')\n",
    "# 'QR 코드 인증'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aea594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 콘센트, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '콘센트' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티탭, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '멀티탭' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19af562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '코드' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f8d5c",
   "metadata": {},
   "source": [
    "#### 기준 4: 역에서 가까워요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('집')\n",
    "# '집 더 가까운 곳이 종류가 없어서', '맛있는 집', '집 와서', '집 가져가서'\n",
    "# 집은 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('지하철')\n",
    "# '지하철 가까워서 그런지', '지하철 가기도 좋구요', '지하철 버스정류장 인접해서 편리해요', '지하철 타기 좋아요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fd892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 위치\n",
    "for sentence in starbucks:\n",
    "    if '위치' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가깝\n",
    "for sentence in starbucks:\n",
    "    if '가깝' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a935ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 근처\n",
    "for sentence in starbucks:\n",
    "    if '근처' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed02840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지하철\n",
    "for sentence in starbucks:\n",
    "    if '지하철' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정류장\n",
    "for sentence in starbucks:\n",
    "    if '정류장' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b478c",
   "metadata": {},
   "source": [
    "#### 고민했던 기준: 영업 시간이 길어요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a4710",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('영업 시간')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('늦게')\n",
    "# '늦게 나오네요', '늦게 찾아갔어요', '늦게 가면', '늦게 받음'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f38f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('새벽')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('늦게까지')\n",
    "# '늦게까지 하는 스벅'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새벽, 전체 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '새벽' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밤 늦다, 전체 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if ('밤' in sentence) and ('늦' in sentence):\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f457b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시간\n",
    "for sentence in starbucks:\n",
    "    if '시간' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5977ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영업\n",
    "for sentence in starbucks:\n",
    "    if '영업' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329bd4d",
   "metadata": {},
   "source": [
    "#### 고민했던 기준: 의자가 편안해요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fce243",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('편해요')\n",
    "# '좌석 간 거리 있고 층 있어 편해요', '엘레베이터 있어 편해요' '한가'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('편하고')\n",
    "# '이용 편하고 친절합니다', '주문 편하고', '작업하기 편하고'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의자\n",
    "for sentence in starbucks:\n",
    "    if '의자' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치\n",
    "for sentence in starbucks:\n",
    "    if '배치' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 편안하다\n",
    "for sentence in starbucks:\n",
    "    if '편안' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의자\n",
    "for sentence in starbucks:\n",
    "    if '의자' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48727b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 편하다\n",
    "for sentence in starbucks:\n",
    "    if ('편해' in sentence) or ('편하' in sentence):\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 푹신, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '푹신' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8076d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 폭신, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '폭신' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f143c3c",
   "metadata": {},
   "source": [
    "#### 기준 5: 좌석이 많아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34040b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text.concordance('넓고')\n",
    "# '서울대 입구 역 아주 가깝고', '지하철', '자리 넓고', '좌석 넓고', '매장 넓고', '층 넓고', '공간 넓고', '사람 많아요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3855b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text.concordance('넓어요')\n",
    "# '넓어요', '자리 편안합니다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6927125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매장\n",
    "for sentence in starbucks:\n",
    "    if '매장' and '넓' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd419eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한가하다\n",
    "for sentence in starbucks:\n",
    "    if '한가' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자리\n",
    "for sentence in starbucks:\n",
    "    if '자리' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc7ac3f",
   "metadata": {},
   "source": [
    "#### 기준 6: 와이파이가 빨라요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fafb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('와이파이')\n",
    "# '와이파이 빵빵'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a76f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와이파이, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '와이파이' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인터넷, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '인터넷' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33301c2",
   "metadata": {},
   "source": [
    "#### 기준 7: 테이블이 넓어요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('테이블')\n",
    "# '테이블 몇개 없어요', '테이블 간격 넓어서 좋아요', '테이블 없어서', '테이블 간격 좁지 않은 편'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfe547",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('책상')\n",
    "# '책상 좋네요', '책상 자리 눈치 싸움 심함'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('넓이')\n",
    "# '적당한 넓이'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea04191",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('높이')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e663be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance('간격')\n",
    "# '의자 간격 좁고', '간격 멀리 떨어져 있는데', '간격 넓혀서'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테이블, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '테이블' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ad6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 책상, 모든 리뷰\n",
    "for sentence in all_reviews:\n",
    "    if '책상' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c128d",
   "metadata": {},
   "source": [
    "### 지도 리뷰와 블로그 리뷰 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8df627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 설입 지도 리뷰\n",
    "df1 = pandas.read_excel('네이버 지도 리뷰 데이터_0523.xlsx')\n",
    "df1.set_index('Unnamed: 0', inplace=True)\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df1 = df1[df1['리뷰'].notnull()]\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 설입 블로그 리뷰\n",
    "df2 = pandas.read_csv('네이버 설입 블로그 리뷰 이모지 제거_0523.csv', encoding = 'utf-8')\n",
    "df2.set_index('Unnamed: 0', inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.columns = ['이름', '블로그 리뷰']   # df 자체를 합쳐버리기 위해 열 이름 변경\n",
    "df2 = df2[df2['블로그 리뷰'].notnull()]\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 데이터 삭제하기\n",
    "# 리뷰까지 중복 값 제거\n",
    "df1 = df1.drop_duplicates(['이름', '평점', '짧은 리뷰', '리뷰'])\n",
    "df2 = df2.drop_duplicates(['이름', '블로그 리뷰'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e01674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지도 리뷰 빈 데이터 (커피볶는여자, 고로커피로스터스) 제거\n",
    "df1 = df1.drop([266, 268])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지도, 블로그 리뷰 각각 컴포즈커피 2로 이름 바꿔주기\n",
    "df1.loc[287]['이름'] = '컴포즈커피 봉천더울림메트로점 2'\n",
    "df2.loc[287]['이름'] = '컴포즈커피 봉천더울림메트로점 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afde36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 블로그 리뷰 이름 중복 데이터 (커피볶는여자, 고로커피로스터스) 합치고 두 번째 행 제거하기\n",
    "import ast\n",
    "\n",
    "df2.loc[40]['블로그 리뷰'] = str(ast.literal_eval(df2.loc[40]['블로그 리뷰']) + ast.literal_eval(df2.loc[266]['블로그 리뷰']))\n",
    "df2.loc[42]['블로그 리뷰'] = str(ast.literal_eval(df2.loc[42]['블로그 리뷰']) + ast.literal_eval(df2.loc[268]['블로그 리뷰']))\n",
    "df2 = df2.drop([266, 268])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81859779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(drop=True, inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48256e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 네이버 리뷰 전체\n",
    "df_naver = pandas.merge(df1, df2, how='outer', on='이름')\n",
    "\n",
    "naver_review = []\n",
    "\n",
    "for i in range(len(df_naver)):\n",
    "    naver_review.append(str(ast.literal_eval(df_naver.loc[i]['리뷰']) + ast.literal_eval(df_naver.loc[i]['블로그 리뷰'])))\n",
    "\n",
    "df_naver['네이버 리뷰 전체'] = naver_review\n",
    "\n",
    "df_naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 리뷰 전체 저장하기\n",
    "df_naver.to_csv('네이버 리뷰 전체_0525.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f1a3d",
   "metadata": {},
   "source": [
    "### 각 기준별 명사 키워드와 함께 자주 쓰이는 형용사, 부사 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3be54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 리뷰 전체 불러오기\n",
    "\n",
    "import ast\n",
    "\n",
    "df = pandas.read_csv('네이버 리뷰 전체_0525.csv', encoding = 'utf-8')\n",
    "df.set_index('Unnamed: 0', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df[df['네이버 리뷰 전체'].notnull()]\n",
    "\n",
    "review_list = []\n",
    "naver_review = df['네이버 리뷰 전체']\n",
    "\n",
    "for i in range(len(naver_review)):\n",
    "    review_list.append(ast.literal_eval(naver_review[i]))\n",
    "\n",
    "len(review_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f194a9",
   "metadata": {},
   "source": [
    "#### 기준 1: 공부하기 좋아요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e7222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword1_공부 = []\n",
    "num = 0\n",
    "f = open(\"keyword1_공부.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num) # error 발생 시 error 처리\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('공부' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword1_공부.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "keyword1_공부_stem = []\n",
    "\n",
    "for k in keyword1_공부:\n",
    "    keyword1_공부_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9be7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 형용사/부사 키워드 (어간) 추출\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword1_공부_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cafa4de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword1_작업 = []\n",
    "num = 0\n",
    "f = open(\"keyword1_작업.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num) # error 발생 시 error 처리\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('작업' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword1_작업.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "keyword1_작업_stem = []\n",
    "\n",
    "for k in keyword1_작업:\n",
    "    keyword1_작업_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee5c22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 형용사/부사 키워드 (어간) 추출\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword1_작업_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b70855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword1_업무 = []\n",
    "num = 0\n",
    "f = open(\"keyword1_업무.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num) # error 발생 시 error 처리\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('업무' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword1_업무.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22baef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "keyword1_업무_stem = []\n",
    "\n",
    "for k in keyword1_업무:\n",
    "    keyword1_업무_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a95353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 형용사/부사 키워드 (어간) 추출\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword1_업무_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ce673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword1_노트북 = []\n",
    "num = 0\n",
    "f = open(\"keyword1_노트북.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num) # error 발생 시 error 처리\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('노트북' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword1_노트북.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "keyword1_노트북_stem = []\n",
    "\n",
    "for k in keyword1_노트북:\n",
    "    keyword1_노트북_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc208105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 형용사/부사 키워드 (어간) 추출\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword1_노트북_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword1_집중 = []\n",
    "num = 0\n",
    "f = open(\"keyword1_집중.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num) # error 발생 시 error 처리\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('집중' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword1_집중.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e556bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "keyword1_집중_stem = []\n",
    "\n",
    "for k in keyword1_집중:\n",
    "    keyword1_집중_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a315ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 형용사/부사 키워드 (어간) 추출\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword1_집중_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcd20f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword1_스터디 = []\n",
    "num = 0\n",
    "f = open(\"keyword1_스터디.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num)  # error 발생 시 error 처리\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('스터디' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword1_스터디.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274da6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd452ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "keyword1_스터디_stem = []\n",
    "\n",
    "for k in keyword1_스터디:\n",
    "    keyword1_스터디_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 형용사/부사 키워드 (어간) 추출\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword1_스터디_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e231a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword1_카공 = []\n",
    "num = 0\n",
    "f = open(\"keyword1_카공.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num) # error 발생 시 error 처리\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('카공' in r) or ('카 공' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword1_카공.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e858bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6890d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword1_카공_stem = []\n",
    "\n",
    "for k in keyword1_카공:\n",
    "    keyword1_카공_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5551f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword1_카공_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f36c3",
   "metadata": {},
   "source": [
    "#### 기준 3: 콘센트가 많아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52527e7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword3 = []\n",
    "num = 0\n",
    "f = open(\"keyword3.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num)\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('콘센트' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword3.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d16913",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a17482",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword3_stem = []\n",
    "\n",
    "for k in keyword3:\n",
    "    keyword2_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a8884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword3_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b2a9f",
   "metadata": {},
   "source": [
    "#### 기준 5: 좌석이 많아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b01cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword5_1 = []\n",
    "num = 0\n",
    "f = open(\"keyword5_의자.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num)\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('의자' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword5_1.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c995c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33619b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "\n",
    "keyword5_1_stem = []\n",
    "\n",
    "for k in keyword4_1:\n",
    "    keyword_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f36dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 형용사/부사 키워드 (어간) 추출\n",
    "\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword5_1_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword5_2 = []\n",
    "num = 0\n",
    "f = open(\"keyword5_자리.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num)\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('자리' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword5_2.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222241b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "\n",
    "keyword5_2_stem = []\n",
    "\n",
    "for k in keyword5_2:\n",
    "    keyword5_2_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50cc8ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 키워드 (어간) 추출\n",
    "\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword5_2_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword5_3 = []\n",
    "num = 0\n",
    "f = open(\"keyword5_좌석.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num)\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('좌석' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword5_3.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b16c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "\n",
    "keyword5_3_stem = []\n",
    "\n",
    "for k in keyword5_3:\n",
    "    keyword5_3_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1650dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 키워드 (어간) 추출\n",
    "\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword5_3_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1989d64",
   "metadata": {},
   "source": [
    "#### 기준 6: 와이파이가 빨라요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword6 = []\n",
    "num = 0\n",
    "f = open(\"keyword6.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num)\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('와이파이' in r) or ('와이 파이' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword6.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aac69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14159e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "\n",
    "keyword6_stem = []\n",
    "\n",
    "for k in keyword6:\n",
    "    keyword6_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330e496",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 키워드 (어간) 추출\n",
    "\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword6_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45da68",
   "metadata": {},
   "source": [
    "#### 기준 7: 테이블이 넓어요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cc675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword7_1 = []\n",
    "num = 0\n",
    "f = open(\"keyword7_테이블.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num)\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('테이블' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword7_1.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword7_1_stem = []\n",
    "\n",
    "for k in keyword7_1:\n",
    "    keyword7_1_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15f933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword7_1_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf84b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "keyword7_2 = []\n",
    "num = 0\n",
    "f = open(\"keyword7_책상.txt\", 'w')\n",
    "\n",
    "for cafe in tqdm(review_list): # 리뷰 리스트 안의 각 카페\n",
    "        for review in cafe: # 각 카페 안의 각 리뷰\n",
    "            try:\n",
    "                new_review = kk.sentences(review) # 각 리뷰 내에서도 다시 문장 단위로 분리 (키워드와의 연관도 높이기 위해)\n",
    "            except:\n",
    "                num += 1\n",
    "                print('error!', num)\n",
    "                #print(review)\n",
    "                #continue\n",
    "            for r in new_review:\n",
    "                if ('책상' in r): # 해당 키워드가 있는 문장만 필터링\n",
    "                        print('====문장====: ', r)\n",
    "                        okt_pos = okt.pos(r) # 각 문장의 품사 태그\n",
    "                        for word, tag in okt_pos:\n",
    "                            if tag in ('Adjective', 'Adverb'): # 문장에 들어 있는 형용사, 부사만 추출\n",
    "                                print(word)\n",
    "                                keyword7_2.append(word)\n",
    "                                f.write(word)\n",
    "                                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 어간 추출\n",
    "\n",
    "keyword7_2_stem = []\n",
    "\n",
    "for k in keyword7_2:\n",
    "    keyword7_2_stem.append(okt.morphs(k, stem=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 많이 쓰인 키워드 (어간) 추출\n",
    "\n",
    "import collections\n",
    "\n",
    "counts = collections.Counter(keyword7_2_stem)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e445fe",
   "metadata": {},
   "source": [
    "## '카공' 지수 도출 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf718c",
   "metadata": {},
   "source": [
    "###  카페별 키워드가 들어간 리뷰의 개수와 전체 리뷰 간의 비율 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bad5d",
   "metadata": {},
   "source": [
    "####  기준 1: 공부하기 좋아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee373b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 안에서 키워드를 발견하면 키워드 기준 -5 ~20자에 해당하는 문자열을 가져와서 서술어, 부정어 분석을 하는 함수.\n",
    "# 한 리뷰 안에서 유효한 키워드를 하나라도 찾으면 바로 다음 리뷰로 넘어감. \n",
    "\n",
    "def get_valid_keyword_reviews(name_list, reviews_list, keyword_list, predicate_list, negative_list):\n",
    "    precise_count_list = []\n",
    "    score_list = []\n",
    "    okt = konlpy.tag.Okt()\n",
    "    \n",
    "    for index, reviews in enumerate(tqdm(reviews_list)):\n",
    "        count = 0\n",
    "        if len(ast.literal_eval(reviews)) >= 20:\n",
    "            for review in ast.literal_eval(reviews):\n",
    "                for keyword in keyword_list:\n",
    "                    if keyword in review:\n",
    "                        idx = review.index(keyword)\n",
    "                        target = review[idx-5:idx+20]\n",
    "                        target_stem = okt.morphs(target, stem=True)\n",
    "                        for predicate in predicate_list:\n",
    "                            valid = True\n",
    "                            if predicate in target_stem:\n",
    "                                for negative in negative_list:\n",
    "                                    if negative in target_stem:\n",
    "                                        valid = False\n",
    "                                        break\n",
    "                                if valid == True :\n",
    "                                    count += 1\n",
    "                                    break\n",
    "                        break\n",
    "            try:\n",
    "                precise_count_list.append({'name': name_list[index], 'count': count, 'total':len(ast.literal_eval(reviews)), 'score': round(count /len(ast.literal_eval(reviews)), 4)  })\n",
    "                score_list.append(round(count/len(ast.literal_eval(reviews)), 4))\n",
    "            except:\n",
    "                precise_count_list.append({'name': name_list[index], 'count': count, 'total':len(ast.literal_eval(reviews)), 'score': 0  })\n",
    "                score_list.append(0)\n",
    "                \n",
    "    # 발견한 키워드 리뷰 갯수 기준 내림차순으로 정렬\n",
    "    precise_sorted_list = sorted(precise_count_list, key=lambda d: d['score'], reverse=True) \n",
    "\n",
    "    score_data_df = pandas.DataFrame(precise_sorted_list)\n",
    "\n",
    "    cols = ['이름', '키워드 리뷰 갯수', '총 리뷰 갯수', '비율']\n",
    "\n",
    "    score_data_df.columns=cols\n",
    "    \n",
    "    return score_data_df, score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a99ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_df = pandas.read_csv('네이버 데이터 최종.csv', index_col = 0)\n",
    "\n",
    "name = list(data_df['이름'])\n",
    "reviews_list = list(data_df['네이버 리뷰 전체'])\n",
    "\n",
    "keyword1_list = ['공부', '작업', '업무', '노트북', '집중', '스터디', '카공']\n",
    "predicate1_list = ['있다', '좋다', '많다', '조용하다', '넓다', '그렇다', '열심히', '가능하다', '괜찮다']\n",
    "negative1_list = ['어렵다', '않다', '아니다']\n",
    "\n",
    "study_df, study_score_list = get_valid_keyword_reviews(name, reviews_list, keyword1_list, predicate1_list, negative1_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df.to_csv('공부하기 좋아요 분석 결과.csv', encoding='utf-8')\n",
    "study_df.to_excel('공부하기 좋아요 분석 결과.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22eb19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 비율의 분포를 확인한다.\n",
    "\n",
    "plt.hist(study_score_list, bins=50, label='bins=100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cad442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 또 다른 코드로 크로스체크하기\n",
    "keywords1 = ['공부', '작업', '업무', '노트북', '집중', '스터디', '카공']\n",
    "keywords2 = ['있다', '좋다', '많다', '조용하다', '넓다', '그렇다', '열심히', '가능하다', '괜찮다']\n",
    "scores = []\n",
    "\n",
    "for i in range(len(review_list)):\n",
    "    count = 0\n",
    "    if len(review_list[i]) >= 20:\n",
    "        for review in review_list[i]:\n",
    "            review_stem = okt.morphs(review, stem=True)\n",
    "            for k in keywords1:\n",
    "                if k in review_stem:\n",
    "                    index = review_stem.index(k)\n",
    "                    keyword_stem = review_stem[index-5:index+10] \n",
    "                    for s in keywords2:\n",
    "                        if (s in keyword_stem) and ('없다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]) and ('않다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]):\n",
    "                            #print(review_stem[review_stem.index(s):review_stem.index(s)+5])\n",
    "                            print('\\n====review====: ', review)\n",
    "                            print('keyword1: ', k)\n",
    "                            print('keyword2: ', s)\n",
    "                            count += 1\n",
    "                            break;\n",
    "                    break;        \n",
    "        if count > 0:\n",
    "            print(df['이름'][i],count,len(review_list[i]),count/len(review_list[i]))\n",
    "            scores.append((df['이름'][i],count,len(review_list[i]),count/len(review_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "scores.sort(key=itemgetter(3), reverse=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b8b53",
   "metadata": {},
   "source": [
    "#### 기준 2: 조용한 분위기예요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pandas.read_csv('네이버 데이터 최종.csv', index_col = 0)\n",
    "\n",
    "name = list(data_df['이름'])\n",
    "reviews_list = list(data_df['네이버 리뷰 전체'])\n",
    "\n",
    "#조용, 차분은 따라오는 서술어 없이 단어 존재 만으로 유의미하기 때문에 서술어 리스트가 없다. \n",
    "# 따라서 get_valid_keyword_reviews 함수에서 서술어 분석을 제외하고 분석을 진행한다. \n",
    "\n",
    "keyword2_list = ['조용', '차분']\n",
    "negative2_list = ['않다', '아니다']\n",
    "\n",
    "quite_count_list = []\n",
    "quite_score_list = []\n",
    "\n",
    "for index, reviews in enumerate(tqdm(reviews_list)):\n",
    "    count = 0\n",
    "    if len(ast.literal_eval(reviews)) >= 20:\n",
    "        for review in ast.literal_eval(reviews):\n",
    "            for keyword in keyword2_list:\n",
    "                if keyword in review:\n",
    "                    idx = review.index(keyword)\n",
    "                    target = review[idx-5:idx+20]\n",
    "                    target_stem = okt.morphs(target, stem=True)\n",
    "                    valid = True\n",
    "                    for negative in negative2_list:\n",
    "                        if negative in target_stem:\n",
    "                            valid = False\n",
    "                            break\n",
    "                    if valid == True :\n",
    "                        count += 1\n",
    "                    break\n",
    "        try:\n",
    "            quite_count_list.append({'name': name[index], 'count': count, 'total':len(ast.literal_eval(reviews)), 'score': round(count /len(ast.literal_eval(reviews)), 4)  })\n",
    "            quite_score_list.append(round(count/len(ast.literal_eval(reviews)), 4))\n",
    "        except:\n",
    "            quite_count_list.append({'name': name[index], 'count': count, 'total':len(ast.literal_eval(reviews)), 'score': 0  })\n",
    "            quite_score_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드가 포함된 리뷰 개수, 전체 리뷰 개수, 그 비율에서 비율을 기준으로 정렬하고,\n",
    "# csv와 excel로 저장한다.\n",
    "\n",
    "quite_sorted_list = sorted(quite_count_list, key=lambda d: d['score'], reverse=True) \n",
    "\n",
    "\n",
    "quite_df = pandas.DataFrame(quite_sorted_list)\n",
    "\n",
    "cols = ['이름', '키워드 리뷰 갯수', '총 리뷰 갯수', '비율']\n",
    "\n",
    "quite_df.columns=cols\n",
    "\n",
    "quite_df.to_csv('조용한 분위기예요 분석 결과.csv', encoding='utf-8')\n",
    "quite_df.to_excel('조용한 분위기예요 분석 결과.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비율의 분포를 확인한다.\n",
    "\n",
    "plt.hist(quite_score_list, bins=50, label='bins=100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24ce7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 또 다른 코드로 크로스체크하기\n",
    "keywords1 = ['조용하다', '차분하다']\n",
    "scores = []\n",
    "\n",
    "for i in range(len(review_list)):\n",
    "    count = 0\n",
    "    if len(review_list[i]) >= 20:\n",
    "        for review in review_list[i]:\n",
    "            review_stem = okt.morphs(review, stem=True)\n",
    "            for k in keywords1:\n",
    "                if k in review_stem:\n",
    "                    if ('없다' not in review_stem[review_stem.index(k):review_stem.index(k)+5]) and ('않다' not in review_stem[review_stem.index(k):review_stem.index(k)+5]):\n",
    "                        print('\\n====review====: ', review)\n",
    "                        print('keyword1: ', k)\n",
    "                        count += 1\n",
    "                        break;      \n",
    "        if count > 0:\n",
    "            print(df['이름'][i],count,len(review_list[i]),count/len(review_list[i]))\n",
    "            scores.append((df['이름'][i],count,len(review_list[i]),count/len(review_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "scores.sort(key=itemgetter(3), reverse=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f9455",
   "metadata": {},
   "source": [
    "#### 기준 3: 콘센트가 많아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0797954",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pandas.read_csv('네이버 데이터 최종.csv', index_col = 0)\n",
    "\n",
    "name = list(data_df['이름'])\n",
    "reviews_list = list(data_df['네이버 리뷰 전체'])\n",
    "\n",
    "keyword3_list = ['콘센트', '멀티탭']\n",
    "predicate3_list = ['많다', '있다']\n",
    "negative3_list = ['없다', '않다']\n",
    "\n",
    "plug_df, plug_score_list = get_valid_keyword_reviews(name, reviews_list, keyword3_list, predicate3_list, negative3_list)\n",
    "\n",
    "# plug_df.to_csv('콘센트가 많아요 분석 결과.csv', encoding='utf-8')\n",
    "# plug_df.to_excel('콘센트가 많아요 분석 결과.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad3f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비율의 분포를 확인한다.\n",
    "\n",
    "plt.hist(plug_score_list, bins=50, label='bins=100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d28b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 또 다른 코드로 크로스체크하기\n",
    "keywords1 = ['콘센트', '멀티탭']\n",
    "keywords2 = ['있다', '많다']\n",
    "scores = []\n",
    "\n",
    "for i in range(len(review_list)):\n",
    "    count = 0\n",
    "    if len(review_list[i]) >= 20:\n",
    "        for review in review_list[i]:\n",
    "            review_stem = okt.morphs(review, stem=True)\n",
    "            for k in keywords1:\n",
    "                if k in review_stem:\n",
    "                    index = review_stem.index(k)\n",
    "                    keyword_stem = review_stem[index-5:index+10] \n",
    "                    for s in keywords2:\n",
    "                        if (s in keyword_stem) and ('없다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]) and ('않다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]):\n",
    "                            #print(review_stem[review_stem.index(s):review_stem.index(s)+5])\n",
    "                            print('\\n====review====: ', review)\n",
    "                            print('keyword1: ', k)\n",
    "                            print('keyword2: ', s)\n",
    "                            count += 1\n",
    "                            break;\n",
    "                    break;        \n",
    "        if count > 0:\n",
    "            print(df['이름'][i],count,len(review_list[i]),count/len(review_list[i]))\n",
    "            scores.append((df['이름'][i],count,len(review_list[i]),count/len(review_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02952bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "scores.sort(key=itemgetter(3), reverse=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c787758",
   "metadata": {},
   "source": [
    "#### 기준 5: 좌석이 많아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pandas.read_csv('네이버 데이터 최종.csv', index_col = 0)\n",
    "\n",
    "name = list(data_df['이름'])\n",
    "reviews_list = list(data_df['네이버 리뷰 전체'])\n",
    "\n",
    "keyword4_list = ['의자', '자리', '좌석', '테이블']\n",
    "predicate4_list = ['많다', '넓다', '넉넉하다', '괘적하다', '널찍하다', '충분하다']\n",
    "negative4_list = ['아니다', '않다']\n",
    "\n",
    "seats_df, seats_score_list = get_valid_keyword_reviews(name, reviews_list, keyword4_list, predicate4_list, negative4_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15cbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "seats_df.to_csv('좌석이 많아요 분석 결과.csv', encoding='utf-8')\n",
    "seats_df.to_excel('좌석이 많아요 분석 결과.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비율의 분포를 확인한다.\n",
    "\n",
    "plt.hist(seats_score_list, bins=50, label='bins=100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또 다른 코드로 크로스체크하기\n",
    "keywords1 = ['의자', '자리', '좌석', '테이블']\n",
    "keywords2 = ['많다', '넓다', '넉넉하다', '쾌적하다', '널찍하다', '충분하다']\n",
    "scores = []\n",
    "\n",
    "for i in range(len(review_list)):\n",
    "    count = 0\n",
    "    if len(review_list[i]) >= 20:\n",
    "        for review in review_list[i]:\n",
    "            review_stem = okt.morphs(review, stem=True)\n",
    "            for k in keywords1:\n",
    "                if k in review_stem:\n",
    "                    index = review_stem.index(k)\n",
    "                    keyword_stem = review_stem[index-5:index+10] \n",
    "                    for s in keywords2:\n",
    "                        if (s in keyword_stem) and ('아니다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]) and ('않다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]):\n",
    "                            #print(review_stem[review_stem.index(s):review_stem.index(s)+5])\n",
    "                            print('\\n====review====: ', review)\n",
    "                            print('keyword1: ', k)\n",
    "                            print('keyword2: ', s)\n",
    "                            count += 1\n",
    "                            break;\n",
    "                    break;        \n",
    "        if count > 0:\n",
    "            print(df['이름'][i],count,len(review_list[i]),count/len(review_list[i]))\n",
    "            scores.append((df['이름'][i],count,len(review_list[i]),count/len(review_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "scores.sort(key=itemgetter(3), reverse=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9c0fa",
   "metadata": {},
   "source": [
    "#### 기준 6: 와이파이가 빨라요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pandas.read_csv('네이버 데이터 최종.csv', index_col = 0)\n",
    "\n",
    "name = list(data_df['이름'])\n",
    "reviews_list = list(data_df['네이버 리뷰 전체'])\n",
    "\n",
    "keyword5_list = ['와이파이', '와이 파이']\n",
    "predicate5_list = ['있다', '빠르다', '편리하다']\n",
    "negative5_list = ['아니다', '않다']\n",
    "\n",
    "wifi_df, wifi_score_list = get_valid_keyword_reviews(name, reviews_list, keyword5_list, predicate5_list, negative5_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c332ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi_df.to_csv('와이파이가 빨라요 분석 결과.csv', encoding='utf-8')\n",
    "wifi_df.to_excel('와이파이가 빨라요 분석 결과.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a02f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 비율의 분포를 확인한다.\n",
    "\n",
    "plt.hist(wifi_score_list, bins=50, label='bins=100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f3042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 또 다른 코드로 크로스체크하기\n",
    "keywords1 = ['와이파이', '와이 파이']\n",
    "keywords2 = ['있다', '빠르다', '편리하다']\n",
    "scores = []\n",
    "\n",
    "for i in range(len(review_list)):\n",
    "    count = 0\n",
    "    if len(review_list[i]) >= 20:\n",
    "        for review in review_list[i]:\n",
    "            review_stem = okt.morphs(review, stem=True)\n",
    "            for k in keywords1:\n",
    "                if k in review_stem:\n",
    "                    index = review_stem.index(k)\n",
    "                    keyword_stem = review_stem[index-5:index+10] \n",
    "                    for s in keywords2:\n",
    "                        if (s in keyword_stem) and ('아니다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]) and ('않다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]):\n",
    "                            #print(review_stem[review_stem.index(s):review_stem.index(s)+5])\n",
    "                            print('\\n====review====: ', review)\n",
    "                            print('keyword1: ', k)\n",
    "                            print('keyword2: ', s)\n",
    "                            count += 1\n",
    "                            break;\n",
    "                    break;        \n",
    "        if count > 0:\n",
    "            print(df['이름'][i],count,len(review_list[i]),count/len(review_list[i]))\n",
    "            scores.append((df['이름'][i],count,len(review_list[i]),count/len(review_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac69807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "scores.sort(key=itemgetter(3), reverse=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9a8de",
   "metadata": {},
   "source": [
    "#### 기준 7: 테이블이 넓어요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d111e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pandas.read_csv('네이버 데이터 최종.csv', index_col = 0)\n",
    "\n",
    "name = list(data_df['이름'])\n",
    "reviews_list = list(data_df['네이버 리뷰 전체'])\n",
    "\n",
    "keyword6_list = ['테이블', '높이']\n",
    "predicate6_list = ['넓다', '크다', '널찍하다', '적당하다']\n",
    "negative6_list = ['아니다', '않다']\n",
    "\n",
    "table_df, table_score_list = get_valid_keyword_reviews(name, reviews_list, keyword6_list, predicate6_list, negative6_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df.to_csv('테이블이 넓어요 분석 결과.csv', encoding='utf-8')\n",
    "table_df.to_excel('테이블이 넓어요 분석 결과.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85037f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비율의 분포를 확인한다.\n",
    "\n",
    "plt.hist(table_score_list, bins=50, label='bins=100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또 다른 코드로 크로스체크하기\n",
    "keywords1 = ['테이블']\n",
    "keywords2 = ['넓다', '크다', '널찍하다', '충분하다', '적당하다']\n",
    "scores = []\n",
    "\n",
    "for i in range(len(review_list)):\n",
    "    count = 0\n",
    "    if len(review_list[i]) >= 20:\n",
    "        for review in review_list[i]:\n",
    "            review_stem = okt.morphs(review, stem=True)\n",
    "            for k in keywords1:\n",
    "                if k in review_stem:\n",
    "                    index = review_stem.index(k)\n",
    "                    keyword_stem = review_stem[index-5:index+10] \n",
    "                    for s in keywords2:\n",
    "                        if (s in keyword_stem) and ('아니다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]) and ('않다' not in review_stem[review_stem.index(s):review_stem.index(s)+5]):\n",
    "                            #print(review_stem[review_stem.index(s):review_stem.index(s)+5])\n",
    "                            print('\\n====review====: ', review)\n",
    "                            print('keyword1: ', k)\n",
    "                            print('keyword2: ', s)\n",
    "                            count += 1\n",
    "                            break;\n",
    "                    break;        \n",
    "        if count > 0:\n",
    "            print(df['이름'][i],count,len(review_list[i]),count/len(review_list[i]))\n",
    "            scores.append((df['이름'][i],count,len(review_list[i]),count/len(review_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c5672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "scores.sort(key=itemgetter(3), reverse=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd979dd",
   "metadata": {},
   "source": [
    "### 기준 4: 역에서 가까워요 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 데이터 최종에서 '근처 역 정보'를 가져와서 m에 해당하는 숫자를 리스트에 저장\n",
    "place_list = df['근처 역 정보']\n",
    "\n",
    "places = []\n",
    "\n",
    "for place in place_list:\n",
    "    places.append(place)\n",
    "    \n",
    "for i in range(len(places)):\n",
    "    if type(places[i]) == str:\n",
    "        places[i] = int(places[i].split('에서')[1].strip('m'))\n",
    "    elif type(places[i]) == float:\n",
    "        places[i] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역에서부터의 거리의 분포를 확인\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(places, bins=50, label='bins=100')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46310e6b",
   "metadata": {},
   "source": [
    "### 네이버 '이런 점이 좋았어요' 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('네이버 데이터 최종.csv', encoding = 'utf-8')\n",
    "df.set_index('Unnamed: 0', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df[df['네이버 리뷰 전체'].notnull()]\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '집중하기 좋아요'라는 키워드가 있는 경우 그 개수와 총 개수를 프린트하기\n",
    "short_keyword = '\"집중하기 좋아요\"'\n",
    "\n",
    "count = -1 #인덱스\n",
    "short_keyword_scores = []  # 여기에 이름과 개수, 총 개수 저장\n",
    "\n",
    "for review in df['짧은 리뷰']:\n",
    "    sum_all = 0\n",
    "    count += 1\n",
    "    if (review == '짧은 리뷰 없음') or (review == 0):\n",
    "            pass\n",
    "    else:\n",
    "        for i in ast.literal_eval(review).values():\n",
    "            sum_all += int(i)\n",
    "        if '\"집중하기 좋아요\"' in ast.literal_eval(review).keys():\n",
    "            keyword_score = int(ast.literal_eval(review)['\"집중하기 좋아요\"'])\n",
    "            keyword_ratio = keyword_score / sum_all\n",
    "            short_keyword_scores.append((df['이름'][count], keyword_score, sum_all, keyword_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b8d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '집중하기 좋아요' 키워드의 개수 순으로 정렬하기\n",
    "from operator import itemgetter\n",
    "short_keyword_scores.sort(key=itemgetter(1), reverse=True)\n",
    "short_keyword_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '집중하기 좋아요' 키워드 개수와 전체 '이런 점이 좋았어요' 리뷰 비율 순으로 정렬하기\n",
    "from operator import itemgetter\n",
    "short_keyword_scores.sort(key=itemgetter(3), reverse=True)\n",
    "short_keyword_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e9b7b",
   "metadata": {},
   "source": [
    "## 최종 카공 점수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = pd.read_csv('공부하기 좋아요 분석 결과.csv', index_col=0)\n",
    "quite_df = pd.read_csv('조용한 분위기예요 분석 결과.csv', index_col=0)\n",
    "plug_df = pd.read_csv('콘센트가 많아요 분석 결과.csv', index_col=0)\n",
    "seats_df = pd.read_csv('좌석이 많아요 분석 결과.csv', index_col=0)\n",
    "wifi_df = pd.read_csv('와이파이가 빨라요 분석 결과.csv', index_col=0)\n",
    "table_df = pd.read_csv('테이블이 넓어요 분석 결과.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51756acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 짧은 리뷰 갯수\n",
    "df = pd.read_csv('네이버 데이터 최종.csv', encoding = 'utf-8')\n",
    "\n",
    "short_review_list = list(df['짧은 리뷰'])\n",
    "name_list = list(df['이름'])\n",
    "\n",
    "short_review_count = []\n",
    "\n",
    "for index, item in enumerate(short_review_list):\n",
    "    if item == '짧은 리뷰 없음':\n",
    "        continue\n",
    "    try:\n",
    "        parsed_item = ast.literal_eval(item)\n",
    "        dic = {'이름': name_list[index], 'count': parsed_item['\"집중하기 좋아요\"']}\n",
    "        short_review_count.append(dic)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "sorted_short_review_count =sorted(short_review_count, key=lambda d:int(d['count']), reverse=True)\n",
    "short_review_df = pd.DataFrame(sorted_short_review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49984ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 정보 데이터 처리\n",
    "final_df = pd.read_csv('네이버 데이터 최종.csv', encoding = 'utf-8')\n",
    "\n",
    "location_list = list(final_df['근처 역 정보'])\n",
    "name_list = list(final_df['이름'])\n",
    "\n",
    "location_data = []\n",
    "\n",
    "for index, data in enumerate(location_list):\n",
    "    if type(data) == float:\n",
    "        dic = {'이름': name_list[index], '거리': 1000}\n",
    "    else:\n",
    "        distance = int(data.split('에서')[1].strip('m'))\n",
    "        dic = {'이름': name_list[index], '거리': distance}\n",
    "        \n",
    "    location_data.append(dic)\n",
    "\n",
    "sorted_location_data =sorted(location_data, key=lambda d:int(d['거리']))\n",
    "location_df = pd.DataFrame(sorted_location_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 구간 별 점수 구분해둔 함수\n",
    "def get_score (grade):\n",
    "    if grade == 1:\n",
    "        score = 100\n",
    "    elif grade == 2:\n",
    "        score = 85\n",
    "    elif grade == 3:\n",
    "        score = 70\n",
    "    elif grade == 4:\n",
    "        score = 55\n",
    "    elif grade == 5:\n",
    "        score = 40\n",
    "    elif grade == 6:\n",
    "        score = 20\n",
    "    return score    \n",
    "\n",
    "# 각 구간별로 해당 점수를 부여하는 함수\n",
    "def assign_score(data, grade):\n",
    "    cafe_list = list(data['이름'])\n",
    "    score = get_score(grade)\n",
    "    \n",
    "    scored_cafe_list = []\n",
    "    \n",
    "    for cafe in cafe_list:\n",
    "        dic ={'name':cafe, 'score': score}\n",
    "        scored_cafe_list.append(dic)\n",
    "    \n",
    "    return scored_cafe_list\n",
    "\n",
    "# DataFrame 별 구간을 분리하고 각 구간별 카페를 slice 한 후 백분위에 따라 점수를 부여한 DataFrame을 반환하는 함수\n",
    "def get_cafe_score_df(df):\n",
    "    row_count = len(df)\n",
    "    grade1= round(row_count * 0.02)\n",
    "    grade2 = round(row_count * 0.05)\n",
    "    grade3 = round(row_count * 0.10)\n",
    "    grade4 = round(row_count * 0.15)\n",
    "    grade5 = round(row_count * 0.20)\n",
    "    grade6 = row_count\n",
    "    \n",
    "    data_grade1 = df.iloc[:grade1]\n",
    "    data_grade2 = df.iloc[grade1:grade2]\n",
    "    data_grade3 = df.iloc[grade2:grade3]\n",
    "    data_grade4 = df.iloc[grade3:grade4]\n",
    "    data_grade5 = df.iloc[grade4:grade5]\n",
    "    data_grade6 = df.iloc[grade5:grade6]\n",
    "    \n",
    "    grade1_scored_list = assign_score(data_grade1, 1)\n",
    "    grade2_scored_list = assign_score(data_grade2, 2)\n",
    "    grade3_scored_list = assign_score(data_grade3, 3)\n",
    "    grade4_scored_list = assign_score(data_grade4, 4)\n",
    "    grade5_scored_list = assign_score(data_grade5, 5)\n",
    "    grade6_scored_list = assign_score(data_grade6, 6)\n",
    "    \n",
    "    data_scored_list = grade1_scored_list + grade2_scored_list + grade3_scored_list + grade4_scored_list + grade5_scored_list + grade6_scored_list\n",
    "\n",
    "    data_score_df = pd.DataFrame(data_scored_list)\n",
    "    \n",
    "    return data_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 데이터는 백분위가이 아니라 절댓 값으로 점수를 주기 때문에 별도로 구간을 설정\n",
    "\n",
    "location_grade1 = location_df[location_df['거리']<= 100]\n",
    "location_grade2 = location_df[(location_df['거리']> 100) & (location_df['거리']<= 200)]\n",
    "location_grade3 = location_df[(location_df['거리']> 200) & (location_df['거리']<= 400)]\n",
    "location_grade4 = location_df[(location_df['거리']> 400) & (location_df['거리']<= 600)]\n",
    "location_grade5 = location_df[(location_df['거리']> 600) & (location_df['거리']<= 800)]\n",
    "location_grade6 = location_df[(location_df['거리']> 800)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "quite_score_df = get_cafe_score_df(quite_df)\n",
    "quite_score_df.columns=['이름', '조용한 분위기예요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_score_df = get_cafe_score_df(study_df)\n",
    "study_score_df.columns=['이름', '공부하기 좋아요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d8bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plug_score_df = get_cafe_score_df(plug_df)\n",
    "plug_score_df.columns=['이름', '콘센트가 많아요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31031ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "seats_score_df = get_cafe_score_df(seats_df)\n",
    "seats_score_df.columns=['이름', '좌석이 많아요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fa1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi_score_df = get_cafe_score_df(wifi_df)\n",
    "wifi_score_df.columns=['이름', '와이파이가 빨라요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_score_df = get_cafe_score_df(table_df)\n",
    "table_score_df.columns=['이름', '테이블이 넓어요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_review_score_df = get_cafe_score_df(short_review_df)\n",
    "short_review_score_df.columns=['이름', '짧은 리뷰']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14615ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade1_location_scored_list = assign_score(location_grade1, 1)\n",
    "grade2_location_scored_list = assign_score(location_grade2, 2)\n",
    "grade3_location_scored_list = assign_score(location_grade3, 3)\n",
    "grade4_location_scored_list = assign_score(location_grade4, 4)\n",
    "grade5_location_scored_list = assign_score(location_grade5, 5)\n",
    "grade6_location_scored_list = assign_score(location_grade6, 6)\n",
    "\n",
    "\n",
    "location_scored_list = grade1_location_scored_list + grade2_location_scored_list + grade3_location_scored_list + grade4_location_scored_list + grade5_location_scored_list + grade6_location_scored_list\n",
    "\n",
    "location_score_df = pd.DataFrame(location_scored_list)\n",
    "\n",
    "location_score_df.columns=['이름', '위치']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 기준별 DataFrame을 하나로 합치기\n",
    "\n",
    "dfs = [study_score_df, quite_score_df,  plug_score_df, table_score_df,seats_score_df, wifi_score_df, short_review_score_df, location_score_df]\n",
    "\n",
    "\n",
    "short_review_score_df, location_score_df\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['이름'],\n",
    "                                            how='left'), dfs).fillna(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미리 정해둔 가중치를 바탕으로 최종 점수 계산\n",
    "df_merged['최종 점수'] = df_merged['공부하기 좋아요']* 0.45 + df_merged['조용한 분위기예요']* 0.1 + df_merged['콘센트가 많아요']* 0.1 + df_merged['테이블이 넓어요']* 0.05 + df_merged['좌석이 많아요']* 0.1 + df_merged['와이파이가 빨라요']* 0.05 + df_merged['짧은 리뷰']* 0.05 + df_merged['위치']* 0.1\n",
    "\n",
    "final_score_df = df_merged.sort_values('최종 점수', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score_df.to_csv('카공하기 좋은 카페 최종 점수.csv', encoding='utf-8')\n",
    "final_score_df.to_excel('카공하기 좋은 카페 최종 점수.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2687e",
   "metadata": {},
   "source": [
    "# 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'시작으로 데이터를 읽어왔고요'\n",
    "df = pd.read_csv('C:/Users/Daniel Hanjoo Rhee/Desktop/경영빅데이터개론 코드 및 데이터/602/카공하기 좋은 카페 최종 점수.csv',index_col = 0 , encoding = 'utf-8')\n",
    "\n",
    "'일단 순위가 딱히 없길레 순위를 메겼습니다.'\n",
    "numbers = [f'{x}위' for x in range(1,248)]\n",
    "df.insert(1,'순위',numbers)\n",
    "\n",
    "'이름, 순위 칼럼만 잘라서 a라는 변수에 저장했습니다.'\n",
    "a = df.iloc[:,0:8] #원래는 a = df.iloc[:,0:2]이다.\n",
    "\n",
    "'그리고는 위치, 최종점수 칼럼만 잘라오고요. 이거를 b라는 변수에 넣었습니다.'\n",
    "b = df.iloc[:,9:]\n",
    "\n",
    "'위에서 잘랐던 두 칼럼들을 합쳐줬고요.'\n",
    "c = pd.concat([a,b],axis=1)\n",
    "\n",
    "'인덱스에 의미없는 숫자가 있길레 새로 만들어줬어요.'\n",
    "c.reset_index(inplace=True)\n",
    "\n",
    "'그리고 기존에 있던 의미 없는 숫자가 있던 칼럼과 위치 칼럼은 지웠습니다.'\n",
    "c.drop('index', inplace=True, axis=1)\n",
    "c.drop('위치', inplace=True, axis=1)\n",
    "# c.drop('최종 점수', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "'역 주위로부터의 거리, 영업시간을 알기위해 다른 csv에서 데이터를 읽어왔어요.'\n",
    "d = pd.read_csv('C:/Users/Daniel Hanjoo Rhee/Desktop/경영빅데이터개론 코드 및 데이터/네이버 데이터 최종.csv', encoding = 'utf-8')\n",
    "dname = d['이름']\n",
    "dtime = d['영업 시간']\n",
    "dstation = d['근처 역 정보']\n",
    "d_name_time_station = pd.concat([dname,dtime,dstation],axis=1)\n",
    "\n",
    "'그리고 위에서 만들었던 데이터프레임과 합쳤습니당.'\n",
    "final_data = pd.merge(c, d_name_time_station, how='inner', on='이름')\n",
    "\n",
    "'합치는 과정에서 최종 점수가 없는 카페가 있을 수도 있기 때문에 그런 카페는 아래 코드로 지워줬어요.'\n",
    "final_data.dropna(subset = ['최종 점수'])\n",
    "\n",
    "name = final_data['이름']\n",
    "rank = final_data['순위']\n",
    "score = final_data['최종 점수']\n",
    "time = final_data['영업 시간']\n",
    "station = final_data['근처 역 정보']\n",
    "\n",
    "final_data\n",
    "'이렇게 최종 점수가 33점이 넘는 친구들만 골라냈습니다.'\n",
    "top25_data = final_data.loc[final_data['최종 점수'] > 33]\n",
    "top10_cafe = top25_data.head(10)\n",
    "# top10_cafe\n",
    "\n",
    "top15_cafe = top25_data.head(15)\n",
    "top15_cafe\n",
    "\n",
    "\n",
    "'위 데이터 프레임을 이미지로 저장한다.'\n",
    "import dataframe_image as dfi\n",
    "dfi.export(top15_cafe, './top15_cafe_image.png', max_cols = -1, max_rows = -1)\n",
    "\n",
    "\n",
    "'top10 cafe의 경도와 위도가 있는 데이터를 읽고, 기존 데이터프레임과 결합했다.'\n",
    "place = pd.read_excel('C:/Users/Daniel Hanjoo Rhee/Desktop/카페경도위도.xlsx')\n",
    "# latitude\n",
    "\n",
    "map_data = pd.merge(top10_cafe, place, how='inner', on='이름')\n",
    "map_data\n",
    "\n",
    "\n",
    "# !pip install folium\n",
    "import folium\n",
    "\n",
    "# 중심 지정\n",
    "lat = map_data['위도'].mean()\n",
    "long =  map_data['경도'].mean()\n",
    "\n",
    "m = folium.Map([lat, long], zoom_start=15)\n",
    "\n",
    "# 지도위에 표시\n",
    "for i in  map_data.index:\n",
    "    sub_lat =  map_data.loc[i, '위도']\n",
    "    sub_long =  map_data.loc[i, '경도']\n",
    "    \n",
    "    ranking = map_data.loc[i, '순위']\n",
    "    \n",
    "    title =  map_data.loc[i, '이름']\n",
    "    hours = map_data.loc[i, '영업 시간']\n",
    "    near_station = map_data.loc[i, '근처 역 정보']\n",
    "    \n",
    "    \n",
    "    my_string = '이름:{}\\n, 영업시간:{}\\n, 근처 역 정보:{}'.format(title,hours,near_station)\n",
    "    \n",
    "    iframe = folium.IFrame(my_string, width=200, height=200)\n",
    "    popup = folium.Popup(iframe, max_width=300)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #지도에 데이터 찍어서 보여주기\n",
    "#     folium.CircleMarker([sub_lat, sub_long], \n",
    "#                         radius=20,\n",
    "#                         color='skyblue',\n",
    "#                         fill_color='skyblue',  \n",
    "#                         tooltip = ranking,\n",
    "#                        popup = popup).add_to(m)\n",
    "\n",
    "\n",
    "    folium.Marker([sub_lat, sub_long], \n",
    "                        tooltip = ranking,\n",
    "                       popup = popup).add_to(m)\n",
    "\n",
    "m.save('top10_cafe.html')\n",
    "m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66eda2a",
   "metadata": {},
   "source": [
    "## 카공 전체 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe54e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22d0538b",
   "metadata": {},
   "source": [
    "## 카공 기준별 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d02ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
